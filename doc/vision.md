# Техническое видение проекта: LLM-ассистент для консультаций клиентов в Telegram

Этот документ описывает техническое видение проекта и служит отправной точкой для разработки.

## Технологии

- **Язык программирования**: Python
- **Telegram API**: aiogram
- **LLM API**: OpenRouter (через реализацию OpenAI client)
- **Контейнеризация**: Docker
- **Тестирование**: pytest
- **Управление зависимостями**: uv
- **Автоматизация**: Make (для сборки, запуска и деплоя)

## Принцип разработки

- **KISS (Keep It Simple, Stupid)**: максимально простые решения без излишеств
- **Минимально жизнеспособный продукт (MVP)** в первую очередь
- **Итеративная разработка** с быстрыми циклами обратной связи
- **Функциональный подход вместо ООП**: предпочтение функциям и модулям вместо сложных объектных иерархий
- **Минимум зависимостей**: использование только необходимых библиотек
- **Ручное тестирование** для начала, автоматизированные тесты для критических компонентов

## Структура проекта

```
/
├── doc/                  # Документация проекта
│   ├── product_idea.md   # Описание идеи продукта
│   └── vision.md         # Техническое видение (этот документ)
├── src/                  # Исходный код
│   ├── bot.py            # Функции для работы с Telegram API
│   ├── llm.py            # Функции для работы с LLM API
│   ├── memory.py         # Функции для работы с памятью диалогов
│   ├── prompts.py        # Функции для работы с промптами
│   └── main.py           # Точка входа
├── tests/                # Тесты
├── prompts/              # Системные промпты для LLM (текстовые файлы)
├── config/               # Конфигурационные файлы
├── Dockerfile            # Для сборки Docker-образа
├── docker-compose.yml    # Для запуска контейнеров
├── Makefile              # Автоматизация задач
├── pyproject.toml        # Конфигурация проекта и зависимости для uv
└── requirements.txt      # Зависимости для совместимости
```

## Архитектура проекта

Простая функциональная архитектура:

- **bot.py** - функции для работы с Telegram API
- **llm.py** - функции для работы с LLM API
- **memory.py** - функции для работы с памятью диалогов
- **prompts.py** - функции для работы с промптами
- **main.py** - точка входа, инициализация и запуск

Поток данных: получение сообщения → извлечение истории → формирование промпта → получение ответа от LLM → отправка ответа → сохранение в память

## Модель данных

Максимально простая модель данных с хранением в оперативной памяти:

- **Диалоги**: словарь Python, где ключ - идентификатор чата (chat_id), значение - список сообщений
- **Сообщение**: словарь с полями `role` (system/user/assistant), `content` (текст) и `timestamp`
- **Конфигурация**: простые переменные окружения или JSON-файл

```python
# Пример структуры данных в памяти
dialogs = {
    "123456789": [  # chat_id из Telegram
        {"role": "system", "content": "Вы ассистент компании...", "timestamp": "2023-01-01T11:59:00"},
        {"role": "user", "content": "Привет", "timestamp": "2023-01-01T12:00:00"},
        {"role": "assistant", "content": "Здравствуйте!", "timestamp": "2023-01-01T12:00:01"}
    ]
}
```

## Работа с LLM

Взаимодействие с LLM через OpenRouter API:

- Использование OpenAI-совместимого клиента для OpenRouter
- Системный промпт с информацией о компании и услугах
- История диалога для контекста
- Простая обработка ответов без сложной логики

Параметры запроса к LLM:
- Модель: Claude 3 Sonnet или GPT-4
- Температура: 0.7 (баланс между креативностью и точностью)
- Максимальная длина ответа: 1000 токенов

## Мониторинг LLM

Минимальный подход к мониторингу:

- Логирование запросов и ответов LLM в файл

## Сценарии работы

Основные сценарии взаимодействия с пользователем:

1. **Приветствие**: знакомство с пользователем
2. **Ответы на вопросы**: предоставление информации и предложение релевантных услуг

## Деплой

Два способа запуска:

- Прямой запуск Python-скриптов для начальной разработки
- Docker Compose для финального деплоя (обязательно)
- Makefile для автоматизации команд

## Подход к конфигурированию

Конфигурация исключительно через файл .env:

- API-ключи (Telegram, OpenRouter)
- Параметры LLM (модель, температура)
- Настройки логирования

## Подход к логгированию

Минималистичный подход к логгированию:

- Стандартный модуль logging в Python
- Логирование в файл и консоль
- Базовые уровни логирования (INFO, ERROR)
